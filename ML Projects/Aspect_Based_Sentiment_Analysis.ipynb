{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json: 142kB [00:00, 16.9MB/s]                    \n",
      "2022-03-11 11:40:18 INFO: Downloading default packages for language: en (English)...\n",
      "2022-03-11 11:40:19 INFO: File exists: /Users/hamza.ahmed/stanza_resources/en/default.zip.\n",
      "2022-03-11 11:40:23 INFO: Finished downloading models and saved to /Users/hamza.ahmed/stanza_resources.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/hamza.ahmed/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/hamza.ahmed/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/hamza.ahmed/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stanza.download('en')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beatles_Paragraph = \"Sgt. Pepper’s applied the concept of the symphony to rock and roll, adding an incredible (and soon overused) dimension to rock and roll. Nothing could have been more ambitious than the current release: The Beatles is the history and synthesis of Western music. And that, of course is what rock and roll is, and that is what the Beatles are. Rock and roll, the first successful art form of the McLuhan age, is a series of increasing hybrids of musical styles, starting from its basic hybrid of country and western music and black American music (blues, if you will). That merger represents the distantly effected marriage of the music of England and Africa, a yin and yang that could be infinitely extended.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "beatles_p1 = nlp(Beatles_Paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_doc_info(doc):\n",
    "    print(f\"Num sentences:\\t{len(doc.sentences)}\")\n",
    "    print(f\"Num tokens:\\t{doc.num_tokens}\")\n",
    "    print(f\"Num words:\\t{doc.num_words}\")\n",
    "    print(f\"Num entities:\\t{len(doc.entities)}\")\n",
    "    \n",
    "def print_sentence_info(sentence):\n",
    "    print(f\"Text: {sentence.text}\")\n",
    "    print(f\"Num tokens:\\t{len(sentence.tokens)}\")\n",
    "    print(f\"Num words:\\t{len(sentence.words)}\")\n",
    "    print(f\"Num entities:\\t{len(sentence.entities)}\")\n",
    "\n",
    "def print_token_info(token):\n",
    "    print(f\"Text:\\t{token.text}\")\n",
    "    print(f\"Start:\\t{token.start_char}\")\n",
    "    print(f\"End:\\t{token.end_char}\")\n",
    "    \n",
    "def print_word_info(word):\n",
    "    print(f\"Text:\\t{word.text}\")\n",
    "    print(f\"Lemma: \\t{word.lemma}\")\n",
    "    print(f\"UPOS: \\t{word.upos}\")\n",
    "    print(f\"XPOS: \\t{word.xpos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/hamza.ahmed/Python Apps/ML Projects/Aspect_Based_Sentiment_Analysis.ipynb Cell 6'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hamza.ahmed/Python%20Apps/ML%20Projects/Aspect_Based_Sentiment_Analysis.ipynb#ch0000003?line=0'>1</a>\u001b[0m \u001b[39m# print_doc_info(beatles_p1)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hamza.ahmed/Python%20Apps/ML%20Projects/Aspect_Based_Sentiment_Analysis.ipynb#ch0000003?line=1'>2</a>\u001b[0m \u001b[39m# print_sentence_info(beatles_p1.sentences[0])\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hamza.ahmed/Python%20Apps/ML%20Projects/Aspect_Based_Sentiment_Analysis.ipynb#ch0000003?line=2'>3</a>\u001b[0m \u001b[39m# print_token_info(beatles_p1.sentences[0].tokens[2])\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hamza.ahmed/Python%20Apps/ML%20Projects/Aspect_Based_Sentiment_Analysis.ipynb#ch0000003?line=3'>4</a>\u001b[0m print_word_info(beatles_p1\u001b[39m.\u001b[39;49msentences[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39mwords[\u001b[39m1\u001b[39m])\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# print_doc_info(beatles_p1)\n",
    "# print_sentence_info(beatles_p1.sentences[0])\n",
    "# print_token_info(beatles_p1.sentences[0].tokens[2])\n",
    "print_word_info(beatles_p1.sentences[1].words[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upos</th>\n",
       "      <th>xpos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sgt.</td>\n",
       "      <td>Sgt.</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pepper</td>\n",
       "      <td>Pepper</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>’s</td>\n",
       "      <td>'s</td>\n",
       "      <td>PART</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>applied</td>\n",
       "      <td>apply</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>could</td>\n",
       "      <td>could</td>\n",
       "      <td>AUX</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>be</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>infinitely</td>\n",
       "      <td>infinitely</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>extended</td>\n",
       "      <td>extend</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           text       lemma   upos xpos\n",
       "0          Sgt.        Sgt.  PROPN  NNP\n",
       "1        Pepper      Pepper  PROPN  NNP\n",
       "2            ’s          's   PART  POS\n",
       "3       applied       apply   VERB  VBN\n",
       "4           the         the    DET   DT\n",
       "..          ...         ...    ...  ...\n",
       "136       could       could    AUX   MD\n",
       "137          be          be    AUX   VB\n",
       "138  infinitely  infinitely    ADV   RB\n",
       "139    extended      extend   VERB  VBN\n",
       "140           .           .  PUNCT    .\n",
       "\n",
       "[141 rows x 4 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_info_df(doc):\n",
    "    \"\"\"\n",
    "    - Parameters: doc (a Stanza Document object)\n",
    "    - Returns: A Pandas DataFrame object with one row for each token in\n",
    "      doc, and columns for text, lemma, upos, and xpos.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for sentence in doc.sentences:\n",
    "        for word in sentence.words:\n",
    "            row = {\n",
    "                \"text\": word.text,\n",
    "                \"lemma\": word.lemma,\n",
    "                \"upos\": word.upos,\n",
    "                \"xpos\": word.xpos,\n",
    "            }\n",
    "            rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "word_info_df(beatles_p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_entity_info(entity):\n",
    "    print(f\"Text:\\t{entity.text}\")\n",
    "    print(f\"Type:\\t{entity.type}\")\n",
    "    print(f\"Start:\\t{entity.start_char}\")\n",
    "    print(f\"End:\\t{entity.end_char}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/hamza.ahmed/Python Apps/ML Projects/Aspect_Based_Sentiment_Analysis.ipynb Cell 9'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hamza.ahmed/Python%20Apps/ML%20Projects/Aspect_Based_Sentiment_Analysis.ipynb#ch0000010?line=0'>1</a>\u001b[0m print_entity_info(beatles_p1\u001b[39m.\u001b[39;49mentities[\u001b[39m0\u001b[39;49m])\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print_entity_info(beatles_p1.entities[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/hamza.ahmed/Python Apps/ML Projects/Aspect_Based_Sentiment_Analysis.ipynb Cell 10'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamza.ahmed/Python%20Apps/ML%20Projects/Aspect_Based_Sentiment_Analysis.ipynb#ch0000006?line=10'>11</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamza.ahmed/Python%20Apps/ML%20Projects/Aspect_Based_Sentiment_Analysis.ipynb#ch0000006?line=11'>12</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mpositive\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hamza.ahmed/Python%20Apps/ML%20Projects/Aspect_Based_Sentiment_Analysis.ipynb#ch0000006?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(sentiment_descriptor(beatles_p1\u001b[39m.\u001b[39;49msentences[\u001b[39m0\u001b[39;49m]))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamza.ahmed/Python%20Apps/ML%20Projects/Aspect_Based_Sentiment_Analysis.ipynb#ch0000006?line=15'>16</a>\u001b[0m \u001b[39m# neutral\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hamza.ahmed/Python%20Apps/ML%20Projects/Aspect_Based_Sentiment_Analysis.ipynb#ch0000006?line=17'>18</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msentence_sentiment_df\u001b[39m(doc):\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def sentiment_descriptor(sentence):\n",
    "    \"\"\"\n",
    "    - Parameters: sentence (a Stanza Sentence object)\n",
    "    - Returns: A string descriptor for the sentiment value of sentence.\n",
    "    \"\"\"\n",
    "    sentiment_value = sentence.sentiment\n",
    "    if (sentiment_value == 0):\n",
    "        return \"negative\"\n",
    "    elif (sentiment_value == 1):\n",
    "        return \"neutral\"\n",
    "    else:\n",
    "        return \"positive\"\n",
    "\n",
    "print(sentiment_descriptor(beatles_p1.sentences[0]))\n",
    "\n",
    "# neutral\n",
    "\n",
    "def sentence_sentiment_df(doc):\n",
    "    \"\"\"\n",
    "    - Parameters: doc (a Stanza Document object)\n",
    "    - Returns: A Pandas DataFrame with one row for each sentence in doc,\n",
    "      and columns for the sentence text and sentiment descriptor.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for sentence in doc.sentences:\n",
    "        row = {\n",
    "            \"text\": sentence.text,\n",
    "            \"sentiment\": sentiment_descriptor(sentence)\n",
    "        }\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_sentiment_df(beatles_p1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_doc(file_path):\n",
    "    with open(file_path) as f:\n",
    "        txt = f.read()\n",
    "    return txt\n",
    "\n",
    "Beatles_PATH = \"/Users/hamza.ahmed/Python Apps/ML Projects/beatles.txt\"\n",
    "Beatles_text = load_text_doc(Beatles_PATH)\n",
    "Beatles = nlp(Beatles_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_person_entities(doc):\n",
    "    return [ent for ent in doc.entities if ent.type == \"PERSON\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def person_df(doc):\n",
    "    \"\"\"\n",
    "    - Parameters: doc (a Stanza Document object)\n",
    "    - Returns: A Pandas DataFrame with one row for each entity in doc\n",
    "      that has a \"PERSON\" type, and and columns text, type, start_char, \n",
    "      and the sentiment of the sentence in which the entity appears.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    persons = select_person_entities(doc)\n",
    "    for person in persons:\n",
    "        row = {\n",
    "            \"text\": person.text,\n",
    "            \"type\": person.type,\n",
    "            \"start_char\": person.start_char,\n",
    "            \"end_char\": person.end_char,\n",
    "            \"sentence_sentiment\": sentiment_descriptor(person._sent)\n",
    "        }\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>start_char</th>\n",
       "      <th>end_char</th>\n",
       "      <th>sentence_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob Dylan</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>75</td>\n",
       "      <td>84</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beatles</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>261</td>\n",
       "      <td>268</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beatles</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>440</td>\n",
       "      <td>447</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pepper</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>1039</td>\n",
       "      <td>1045</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pepper</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>1079</td>\n",
       "      <td>1085</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text    type  start_char  end_char sentence_sentiment\n",
       "0  Bob Dylan  PERSON          75        84            neutral\n",
       "1    Beatles  PERSON         261       268           positive\n",
       "2    Beatles  PERSON         440       447            neutral\n",
       "3     Pepper  PERSON        1039      1045           positive\n",
       "4     Pepper  PERSON        1079      1085           positive"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "characters = person_df(Beatles)\n",
    "display(characters.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def num_unique_items(df, col):\n",
    "    return len(df[col].unique())\n",
    "\n",
    "num_unique_items(characters, \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Beatles           22\n",
       "Paul               9\n",
       "John               9\n",
       "Pepper             5\n",
       "Ringo              4\n",
       "George             3\n",
       "Blackbird          3\n",
       "Bob Dylan          2\n",
       "Paul McCartney     2\n",
       "Obladi Oblada      2\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def frequency_count(df, col, limit=10):\n",
    "    return df[col].value_counts().head(limit)\n",
    "\n",
    "frequency_count(characters, \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters in the most negative settings.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentence_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Ringo</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>John</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Paul</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Band</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Rocky Raccoon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             text  sentence_sentiment\n",
       "32          Ringo                  -3\n",
       "18           John                  -2\n",
       "27           Paul                  -1\n",
       "0            Band                   0\n",
       "33  Rocky Raccoon                   0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters in the most positive settings\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentence_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Paul McCartney</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Obladi Oblada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Pepper</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beatles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blackbird</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              text  sentence_sentiment\n",
       "28  Paul McCartney                   1\n",
       "26   Obladi Oblada                   1\n",
       "29          Pepper                   2\n",
       "1          Beatles                   2\n",
       "2        Blackbird                   3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sentiment_descriptor_to_val(descriptor):\n",
    "    \"\"\"\n",
    "    - Parameters: descriptor (\"negative\", \"neutral\", or \"positive\")\n",
    "    - Returns: -1 for \"negative\", 0 for \"neutral\", 1 for \"positive\"\n",
    "    \"\"\"\n",
    "    if descriptor == \"negative\":\n",
    "        return -1\n",
    "    elif descriptor == \"neutral\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def character_sentiment(df):\n",
    "    \"\"\"\n",
    "    - Parameters: df (Pandas DataFrame)\n",
    "    - df must contain \"text\" and \"sentiment_descriptor\" columns.\n",
    "    - Returns: \n",
    "    \"\"\"\n",
    "    sentiment = df.copy()\n",
    "    sentiment[\"sentence_sentiment\"] = [\n",
    "        sentiment_descriptor_to_val(s) for s\n",
    "        in sentiment[\"sentence_sentiment\"]\n",
    "    ]\n",
    "    sentiment = sentiment[[\"text\", \"sentence_sentiment\"]]\n",
    "    sentiment = sentiment.groupby(\"text\").sum().reset_index()\n",
    "    \n",
    "    return sentiment.sort_values(\"sentence_sentiment\")\n",
    "\n",
    "sentiment_df = character_sentiment(characters)\n",
    "\n",
    "print(\"Characters in the most negative settings.\")\n",
    "display(sentiment_df.head(5))\n",
    "\n",
    "print(\"Characters in the most positive settings\")\n",
    "display(sentiment_df.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
